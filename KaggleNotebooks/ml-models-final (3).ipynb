{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7572390,"sourceType":"datasetVersion","datasetId":4408352},{"sourceId":7579350,"sourceType":"datasetVersion","datasetId":4412079}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"------------------------------------  Snowball stemmer with pos + stopwords + tokenize _ tf-idf vectorizer -------------------------------------","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer \nimport pandas as pd\nfrom nltk.tokenize import word_tokenize\nfrom nltk import pos_tag\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom nltk.stem import SnowballStemmer \ntrain_sentiments = pd.read_csv(\"/kaggle/input/dataset/train.csv/train.csv\")\ntest_sentiments = pd.read_csv(\"/kaggle/input/dataset/test.csv/test.csv\")\n\n# Text preprocessing function with stemming and POS tagging\ndef preprocess_sreview(review):\n    tokens = word_tokenize(review)\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token.lower() not in stop_words]\n\n    # Use SnowballStemmer for stemming\n    stemmer = SnowballStemmer(\"english\")\n    tokens = [stemmer.stem(token) for token in tokens]\n\n    # Perform POS tagging\n    pos_tags = pos_tag(tokens)\n    tokens = [word + '_' + pos for word, pos in pos_tags]\n\n    return ' '.join(tokens)\n\ntrain_sentiments['processed_reviews'] = train_sentiments['review'].apply(preprocess_sreview)\ntest_sentiments['processed_reviews'] = test_sentiments['review'].apply(preprocess_sreview)\n\n# Vectorize the text data using TF-IDF\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\ntrain_tfidf = tfidf_vectorizer.fit_transform(train_sentiments['processed_reviews'])\ntest_tfidf = tfidf_vectorizer.transform(test_sentiments['processed_reviews'] )","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-06T15:46:12.810940Z","iopub.execute_input":"2024-02-06T15:46:12.811660Z","iopub.status.idle":"2024-02-06T16:00:29.291739Z","shell.execute_reply.started":"2024-02-06T15:46:12.811592Z","shell.execute_reply":"2024-02-06T16:00:29.290698Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Naive Bayes\nnb_model = MultinomialNB()\nnb_model.fit(train_tfidf, train_sentiments['sentiment'])\nnb_predictions = nb_model.predict(test_tfidf)\nnb_accuracy = accuracy_score(test_sentiments['sentiment'], nb_predictions)\nprint(\"Naive Bayes Accuracy:\", nb_accuracy)\nprint(\"Classification Report for Naive Bayes:\\n\", classification_report(test_sentiments['sentiment'], nb_predictions))\nprint(nb_predictions)\nprint(\"/n\")\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(train_tfidf, train_sentiments['sentiment'])\nrf_predictions = rf_model.predict(test_tfidf)\nrf_accuracy = accuracy_score(test_sentiments['sentiment'], rf_predictions)\nprint(\"Random Forest Accuracy:\", rf_accuracy)\nprint(\"Classification Report for Random Forest:\\n\", classification_report(test_sentiments['sentiment'], rf_predictions))\nprint(rf_predictions)\n\n# Neural Network\nnn_model = MLPClassifier(hidden_layer_sizes=(64,), max_iter=100, random_state=42)\nnn_model.fit(train_tfidf, train_sentiments['sentiment'])\nnn_predictions = nn_model.predict(test_tfidf)\nnn_accuracy = accuracy_score(test_sentiments['sentiment'], nn_predictions)\nprint(\"Neural Network Accuracy:\", nn_accuracy)\nprint(\"Classification Report for Neural Network:\\n\", classification_report(test_sentiments['sentiment'], nn_predictions))\n\n\n# Decision Tree\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(train_tfidf, train_sentiments['sentiment'])\ndt_predictions = dt_model.predict(test_tfidf)\ndt_accuracy = accuracy_score(test_sentiments['sentiment'], dt_predictions)\nprint(\"Decision Tree Accuracy:\", dt_accuracy)\nprint(\"Classification Report for Decision Tree:\\n\", classification_report(test_sentiments['sentiment'], dt_predictions))\nprint(\"/n\")\n\n# Gradient Boosting\ngb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\ngb_model.fit(train_tfidf, train_sentiments['sentiment'])\ngb_predictions = gb_model.predict(test_tfidf)\ngb_accuracy = accuracy_score(test_sentiments['sentiment'], gb_predictions)\nprint(\"Gradient Boosting Accuracy:\", gb_accuracy)\nprint(\"Classification Report for Gradient Boosting:\\n\", classification_report(test_sentiments['sentiment'], gb_predictions))\n\n# k-NN\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(train_tfidf, train_sentiments['sentiment'])\nknn_predictions = knn_model.predict(test_tfidf)\nknn_accuracy = accuracy_score(test_sentiments['sentiment'], knn_predictions)\nprint(\"k-NN Accuracy:\", knn_accuracy)\nprint(\"Classification Report for k-NN:\\n\", classification_report(test_sentiments['sentiment'], knn_predictions))\nprint(\"/n\")\n\n# Stacking\nstacking_model = StackingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model),('gb', gb_model)],\n    final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42)\n)\nstacking_model.fit(train_tfidf, train_sentiments['sentiment'])\nstacking_predictions = stacking_model.predict(test_tfidf)\nstacking_accuracy = accuracy_score(test_sentiments['sentiment'], stacking_predictions)\nprint(\"Stacking Accuracy:\", stacking_accuracy)\nprint(\"Classification Report for Stacking:\\n\", classification_report(test_sentiments['sentiment'], stacking_predictions))\nprint(\"/n\")\n\n# Bagging\nbagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\nbagging_model.fit(train_tfidf, train_sentiments['sentiment'])\nbagging_predictions = bagging_model.predict(test_tfidf)\nbagging_accuracy = accuracy_score(test_sentiments['sentiment'], bagging_predictions)\nprint(\"Bagging Accuracy:\", bagging_accuracy)\nprint(\"Classification Report for Bagging:\\n\", classification_report(test_sentiments['sentiment'], bagging_predictions))\nprint(\"/n\")\n\n# Voting Classifier\nvoting_model = VotingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model), ('gb', gb_model)],\n    voting='hard'\n)\nvoting_model.fit(train_tfidf, train_sentiments['sentiment'])\nvoting_predictions = voting_model.predict(test_tfidf)\nvoting_accuracy = accuracy_score(test_sentiments['sentiment'], voting_predictions)\nprint(\"Voting Classifier Accuracy:\", voting_accuracy)\nprint(\"Classification Report for Voting Classifier:\\n\", classification_report(test_sentiments['sentiment'], voting_predictions))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-06T16:01:57.718490Z","iopub.execute_input":"2024-02-06T16:01:57.719154Z","iopub.status.idle":"2024-02-06T19:06:07.861549Z","shell.execute_reply.started":"2024-02-06T16:01:57.719120Z","shell.execute_reply":"2024-02-06T19:06:07.860472Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy: 0.84435\nClassification Report for Naive Bayes:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.84      0.84      9935\n    positive       0.84      0.85      0.85     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n['positive' 'positive' 'negative' ... 'negative' 'positive' 'negative']\n/n\nRandom Forest Accuracy: 0.83315\nClassification Report for Random Forest:\n               precision    recall  f1-score   support\n\n    negative       0.83      0.84      0.83      9935\n    positive       0.84      0.83      0.83     10065\n\n    accuracy                           0.83     20000\n   macro avg       0.83      0.83      0.83     20000\nweighted avg       0.83      0.83      0.83     20000\n\n['positive' 'positive' 'negative' ... 'negative' 'positive' 'negative']\nNeural Network Accuracy: 0.84755\nClassification Report for Neural Network:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.85      0.85      9935\n    positive       0.85      0.85      0.85     10065\n\n    accuracy                           0.85     20000\n   macro avg       0.85      0.85      0.85     20000\nweighted avg       0.85      0.85      0.85     20000\n\nDecision Tree Accuracy: 0.69425\nClassification Report for Decision Tree:\n               precision    recall  f1-score   support\n\n    negative       0.69      0.70      0.70      9935\n    positive       0.70      0.68      0.69     10065\n\n    accuracy                           0.69     20000\n   macro avg       0.69      0.69      0.69     20000\nweighted avg       0.69      0.69      0.69     20000\n\n/n\nGradient Boosting Accuracy: 0.79755\nClassification Report for Gradient Boosting:\n               precision    recall  f1-score   support\n\n    negative       0.83      0.75      0.79      9935\n    positive       0.77      0.84      0.81     10065\n\n    accuracy                           0.80     20000\n   macro avg       0.80      0.80      0.80     20000\nweighted avg       0.80      0.80      0.80     20000\n\nk-NN Accuracy: 0.6682\nClassification Report for k-NN:\n               precision    recall  f1-score   support\n\n    negative       0.65      0.73      0.69      9935\n    positive       0.70      0.60      0.65     10065\n\n    accuracy                           0.67     20000\n   macro avg       0.67      0.67      0.67     20000\nweighted avg       0.67      0.67      0.67     20000\n\n/n\nStacking Accuracy: 0.8614\nClassification Report for Stacking:\n               precision    recall  f1-score   support\n\n    negative       0.86      0.86      0.86      9935\n    positive       0.86      0.86      0.86     10065\n\n    accuracy                           0.86     20000\n   macro avg       0.86      0.86      0.86     20000\nweighted avg       0.86      0.86      0.86     20000\n\n/n\nBagging Accuracy: 0.7939\nClassification Report for Bagging:\n               precision    recall  f1-score   support\n\n    negative       0.79      0.79      0.79      9935\n    positive       0.79      0.80      0.80     10065\n\n    accuracy                           0.79     20000\n   macro avg       0.79      0.79      0.79     20000\nweighted avg       0.79      0.79      0.79     20000\n\n/n\nVoting Classifier Accuracy: 0.841\nClassification Report for Voting Classifier:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.83      0.84      9935\n    positive       0.84      0.85      0.84     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"------------------------ Snowball stemmer with pos _ count vectorizer ---------------------","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer \nimport pandas as pd\nfrom nltk.tokenize import word_tokenize\nfrom nltk import pos_tag\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom nltk.stem import SnowballStemmer \ntrain_sentiments = pd.read_csv(\"/kaggle/input/sentiments/train.csv/train.csv\")\ntest_sentiments = pd.read_csv(\"/kaggle/input/sentiments/test.csv/test.csv\")\n\n# Text preprocessing function with stemming and POS tagging\ndef preprocess_sreview(review):\n    tokens = word_tokenize(review)\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token.lower() not in stop_words]\n\n    # Use SnowballStemmer for stemming\n    stemmer = SnowballStemmer(\"english\")\n    tokens = [stemmer.stem(token) for token in tokens]\n\n    # Perform POS tagging\n    pos_tags = pos_tag(tokens)\n    tokens = [word + '_' + pos for word, pos in pos_tags]\n\n    return ' '.join(tokens)\n\ntrain_sentiments['processed_reviews'] = train_sentiments['review'].apply(preprocess_sreview)\ntest_sentiments['processed_reviews'] = test_sentiments['review'].apply(preprocess_sreview)\n\n# Vectorize the text data using CountVectorizer\ncount_vectorizer = CountVectorizer(max_features=5000)\ntrain_tfidf = count_vectorizer.fit_transform(train_sentiments['processed_reviews'])\ntest_tfidf = count_vectorizer.transform(test_sentiments['processed_reviews'])","metadata":{"execution":{"iopub.status.busy":"2024-02-07T08:59:01.078452Z","iopub.execute_input":"2024-02-07T08:59:01.078828Z","iopub.status.idle":"2024-02-07T09:13:41.962232Z","shell.execute_reply.started":"2024-02-07T08:59:01.078798Z","shell.execute_reply":"2024-02-07T09:13:41.961342Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Naive Bayes\nnb_model = MultinomialNB()\nnb_model.fit(train_tfidf, train_sentiments['sentiment'])\nnb_predictions = nb_model.predict(test_tfidf)\nnb_accuracy = accuracy_score(test_sentiments['sentiment'], nb_predictions)\nprint(\"Naive Bayes Accuracy:\", nb_accuracy)\nprint(\"Classification Report for Naive Bayes:\\n\", classification_report(test_sentiments['sentiment'], nb_predictions))\nprint(\"\\n\")\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(train_tfidf, train_sentiments['sentiment'])\nrf_predictions = rf_model.predict(test_tfidf)\nrf_accuracy = accuracy_score(test_sentiments['sentiment'], rf_predictions)\nprint(\"Random Forest Accuracy:\", rf_accuracy)\nprint(\"Classification Report for Random Forest:\\n\", classification_report(test_sentiments['sentiment'], rf_predictions))\nprint(\"\\n\")\n\n# Neural Network\nnn_model = MLPClassifier(hidden_layer_sizes=(64,), max_iter=100, random_state=42)\nnn_model.fit(train_tfidf, train_sentiments['sentiment'])\nnn_predictions = nn_model.predict(test_tfidf)\nnn_accuracy = accuracy_score(test_sentiments['sentiment'], nn_predictions)\nprint(\"Neural Network Accuracy:\", nn_accuracy)\nprint(\"Classification Report for Neural Network:\\n\", classification_report(test_sentiments['sentiment'], nn_predictions))\nprint(\"\\n\")\n\n# Decision Tree\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(train_tfidf, train_sentiments['sentiment'])\ndt_predictions = dt_model.predict(test_tfidf)\ndt_accuracy = accuracy_score(test_sentiments['sentiment'], dt_predictions)\nprint(\"Decision Tree Accuracy:\", dt_accuracy)\nprint(\"Classification Report for Decision Tree:\\n\", classification_report(test_sentiments['sentiment'], dt_predictions))\nprint(\"\\n\")\n\n# Gradient Boosting\ngb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\ngb_model.fit(train_tfidf, train_sentiments['sentiment'])\ngb_predictions = gb_model.predict(test_tfidf)\ngb_accuracy = accuracy_score(test_sentiments['sentiment'], gb_predictions)\nprint(\"Gradient Boosting Accuracy:\", gb_accuracy)\nprint(\"Classification Report for Gradient Boosting:\\n\", classification_report(test_sentiments['sentiment'], gb_predictions))\nprint(\"\\n\")\n\n# k-NN\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(train_tfidf, train_sentiments['sentiment'])\nknn_predictions = knn_model.predict(test_tfidf)\nknn_accuracy = accuracy_score(test_sentiments['sentiment'], knn_predictions)\nprint(\"k-NN Accuracy:\", knn_accuracy)\nprint(\"Classification Report for k-NN:\\n\", classification_report(test_sentiments['sentiment'], knn_predictions))\nprint(\"\\n\")\n\n# Stacking\nstacking_model = StackingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model),('gb', gb_model)],\n    final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42)\n)\nstacking_model.fit(train_tfidf, train_sentiments['sentiment'])\nstacking_predictions = stacking_model.predict(test_tfidf)\nstacking_accuracy = accuracy_score(test_sentiments['sentiment'], stacking_predictions)\nprint(\"Stacking Accuracy:\", stacking_accuracy)\nprint(\"Classification Report for Stacking:\\n\", classification_report(test_sentiments['sentiment'], stacking_predictions))\nprint(\"\\n\")\n\n# Bagging\nbagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\nbagging_model.fit(train_tfidf, train_sentiments['sentiment'])\nbagging_predictions = bagging_model.predict(test_tfidf)\nbagging_accuracy = accuracy_score(test_sentiments['sentiment'], bagging_predictions)\nprint(\"Bagging Accuracy:\", bagging_accuracy)\nprint(\"Classification Report for Bagging:\\n\", classification_report(test_sentiments['sentiment'], bagging_predictions))\nprint(\"\\n\")\n\n# Voting Classifier\nvoting_model = VotingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model), ('gb', gb_model)],\n    voting='hard'\n)\nvoting_model.fit(train_tfidf, train_sentiments['sentiment'])\nvoting_predictions = voting_model.predict(test_tfidf)\nvoting_accuracy = accuracy_score(test_sentiments['sentiment'], voting_predictions)\nprint(\"Voting Classifier Accuracy:\", voting_accuracy)\nprint(\"Classification Report for Voting Classifier:\\n\", classification_report(test_sentiments['sentiment'], voting_predictions))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-07T09:13:59.941512Z","iopub.execute_input":"2024-02-07T09:13:59.941900Z","iopub.status.idle":"2024-02-07T10:14:23.354445Z","shell.execute_reply.started":"2024-02-07T09:13:59.941875Z","shell.execute_reply":"2024-02-07T10:14:23.353506Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy: 0.83735\nClassification Report for Naive Bayes:\n               precision    recall  f1-score   support\n\n    negative       0.83      0.84      0.84      9935\n    positive       0.84      0.83      0.84     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n\n\nRandom Forest Accuracy: 0.83265\nClassification Report for Random Forest:\n               precision    recall  f1-score   support\n\n    negative       0.83      0.84      0.83      9935\n    positive       0.84      0.82      0.83     10065\n\n    accuracy                           0.83     20000\n   macro avg       0.83      0.83      0.83     20000\nweighted avg       0.83      0.83      0.83     20000\n\n\n\nNeural Network Accuracy: 0.8581\nClassification Report for Neural Network:\n               precision    recall  f1-score   support\n\n    negative       0.86      0.85      0.86      9935\n    positive       0.86      0.86      0.86     10065\n\n    accuracy                           0.86     20000\n   macro avg       0.86      0.86      0.86     20000\nweighted avg       0.86      0.86      0.86     20000\n\n\n\nDecision Tree Accuracy: 0.7009\nClassification Report for Decision Tree:\n               precision    recall  f1-score   support\n\n    negative       0.70      0.70      0.70      9935\n    positive       0.70      0.71      0.70     10065\n\n    accuracy                           0.70     20000\n   macro avg       0.70      0.70      0.70     20000\nweighted avg       0.70      0.70      0.70     20000\n\n\n\nGradient Boosting Accuracy: 0.79745\nClassification Report for Gradient Boosting:\n               precision    recall  f1-score   support\n\n    negative       0.83      0.75      0.79      9935\n    positive       0.77      0.85      0.81     10065\n\n    accuracy                           0.80     20000\n   macro avg       0.80      0.80      0.80     20000\nweighted avg       0.80      0.80      0.80     20000\n\n\n\nk-NN Accuracy: 0.59095\nClassification Report for k-NN:\n               precision    recall  f1-score   support\n\n    negative       0.58      0.67      0.62      9935\n    positive       0.61      0.51      0.56     10065\n\n    accuracy                           0.59     20000\n   macro avg       0.59      0.59      0.59     20000\nweighted avg       0.59      0.59      0.59     20000\n\n\n\nStacking Accuracy: 0.85405\nClassification Report for Stacking:\n               precision    recall  f1-score   support\n\n    negative       0.86      0.85      0.85      9935\n    positive       0.85      0.86      0.86     10065\n\n    accuracy                           0.85     20000\n   macro avg       0.85      0.85      0.85     20000\nweighted avg       0.85      0.85      0.85     20000\n\n\n\nBagging Accuracy: 0.7924\nClassification Report for Bagging:\n               precision    recall  f1-score   support\n\n    negative       0.80      0.78      0.79      9935\n    positive       0.79      0.81      0.80     10065\n\n    accuracy                           0.79     20000\n   macro avg       0.79      0.79      0.79     20000\nweighted avg       0.79      0.79      0.79     20000\n\n\n\nVoting Classifier Accuracy: 0.83145\nClassification Report for Voting Classifier:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.82      0.83      9935\n    positive       0.83      0.84      0.83     10065\n\n    accuracy                           0.83     20000\n   macro avg       0.83      0.83      0.83     20000\nweighted avg       0.83      0.83      0.83     20000\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"------------------------ Snowball stemmer without pos _ count vectorizer ---------------------","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer \nimport pandas as pd\nfrom nltk.tokenize import word_tokenize\nfrom nltk import pos_tag\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom nltk.stem import SnowballStemmer \ntrain_sentiments = pd.read_csv(\"/kaggle/input/sentiments/train.csv/train.csv\")\ntest_sentiments = pd.read_csv(\"/kaggle/input/sentiments/test.csv/test.csv\")\n\n# Text preprocessing function with stemming and POS tagging\ndef preprocess_sreview(review):\n    tokens = word_tokenize(review)\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token.lower() not in stop_words]\n\n    # Use SnowballStemmer for stemming\n    stemmer = SnowballStemmer(\"english\")\n    tokens = [stemmer.stem(token) for token in tokens]\n\n    return ' '.join(tokens)\n\ntrain_sentiments['processed_reviews'] = train_sentiments['review'].apply(preprocess_sreview)\ntest_sentiments['processed_reviews'] = test_sentiments['review'].apply(preprocess_sreview)\n\n# Vectorize the text data using CountVectorizer\ncount_vectorizer = CountVectorizer(max_features=5000)\ntrain_tfidf = count_vectorizer.fit_transform(train_sentiments['processed_reviews'])\ntest_tfidf = count_vectorizer.transform(test_sentiments['processed_reviews'])","metadata":{"execution":{"iopub.status.busy":"2024-02-07T10:59:56.806483Z","iopub.execute_input":"2024-02-07T10:59:56.806913Z","iopub.status.idle":"2024-02-07T11:05:25.036724Z","shell.execute_reply.started":"2024-02-07T10:59:56.806880Z","shell.execute_reply":"2024-02-07T11:05:25.035280Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Naive Bayes\nnb_model = MultinomialNB()\nnb_model.fit(train_tfidf, train_sentiments['sentiment'])\nnb_predictions = nb_model.predict(test_tfidf)\nnb_accuracy = accuracy_score(test_sentiments['sentiment'], nb_predictions)\nprint(\"Naive Bayes Accuracy:\", nb_accuracy)\nprint(\"Classification Report for Naive Bayes:\\n\", classification_report(test_sentiments['sentiment'], nb_predictions))\nprint(\"\\n\")\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(train_tfidf, train_sentiments['sentiment'])\nrf_predictions = rf_model.predict(test_tfidf)\nrf_accuracy = accuracy_score(test_sentiments['sentiment'], rf_predictions)\nprint(\"Random Forest Accuracy:\", rf_accuracy)\nprint(\"Classification Report for Random Forest:\\n\", classification_report(test_sentiments['sentiment'], rf_predictions))\nprint(\"\\n\")\n\n# Neural Network\nnn_model = MLPClassifier(hidden_layer_sizes=(64,), max_iter=100, random_state=42)\nnn_model.fit(train_tfidf, train_sentiments['sentiment'])\nnn_predictions = nn_model.predict(test_tfidf)\nnn_accuracy = accuracy_score(test_sentiments['sentiment'], nn_predictions)\nprint(\"Neural Network Accuracy:\", nn_accuracy)\nprint(\"Classification Report for Neural Network:\\n\", classification_report(test_sentiments['sentiment'], nn_predictions))\nprint(\"\\n\")\n\n# Decision Tree\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(train_tfidf, train_sentiments['sentiment'])\ndt_predictions = dt_model.predict(test_tfidf)\ndt_accuracy = accuracy_score(test_sentiments['sentiment'], dt_predictions)\nprint(\"Decision Tree Accuracy:\", dt_accuracy)\nprint(\"Classification Report for Decision Tree:\\n\", classification_report(test_sentiments['sentiment'], dt_predictions))\nprint(\"\\n\")\n\n# Gradient Boosting\ngb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\ngb_model.fit(train_tfidf, train_sentiments['sentiment'])\ngb_predictions = gb_model.predict(test_tfidf)\ngb_accuracy = accuracy_score(test_sentiments['sentiment'], gb_predictions)\nprint(\"Gradient Boosting Accuracy:\", gb_accuracy)\nprint(\"Classification Report for Gradient Boosting:\\n\", classification_report(test_sentiments['sentiment'], gb_predictions))\nprint(\"\\n\")\n\n# k-NN\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(train_tfidf, train_sentiments['sentiment'])\nknn_predictions = knn_model.predict(test_tfidf)\nknn_accuracy = accuracy_score(test_sentiments['sentiment'], knn_predictions)\nprint(\"k-NN Accuracy:\", knn_accuracy)\nprint(\"Classification Report for k-NN:\\n\", classification_report(test_sentiments['sentiment'], knn_predictions))\nprint(\"\\n\")\n\n# Stacking\nstacking_model = StackingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model),('gb', gb_model)],\n    final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42)\n)\nstacking_model.fit(train_tfidf, train_sentiments['sentiment'])\nstacking_predictions = stacking_model.predict(test_tfidf)\nstacking_accuracy = accuracy_score(test_sentiments['sentiment'], stacking_predictions)\nprint(\"Stacking Accuracy:\", stacking_accuracy)\nprint(\"Classification Report for Stacking:\\n\", classification_report(test_sentiments['sentiment'], stacking_predictions))\nprint(\"\\n\")\n\n# Bagging\nbagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\nbagging_model.fit(train_tfidf, train_sentiments['sentiment'])\nbagging_predictions = bagging_model.predict(test_tfidf)\nbagging_accuracy = accuracy_score(test_sentiments['sentiment'], bagging_predictions)\nprint(\"Bagging Accuracy:\", bagging_accuracy)\nprint(\"Classification Report for Bagging:\\n\", classification_report(test_sentiments['sentiment'], bagging_predictions))\nprint(\"\\n\")\n\n# Voting Classifier\nvoting_model = VotingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model), ('gb', gb_model)],\n    voting='hard'\n)\nvoting_model.fit(train_tfidf, train_sentiments['sentiment'])\nvoting_predictions = voting_model.predict(test_tfidf)\nvoting_accuracy = accuracy_score(test_sentiments['sentiment'], voting_predictions)\nprint(\"Voting Classifier Accuracy:\", voting_accuracy)\nprint(\"Classification Report for Voting Classifier:\\n\", classification_report(test_sentiments['sentiment'], voting_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-02-07T11:06:51.353559Z","iopub.execute_input":"2024-02-07T11:06:51.354011Z","iopub.status.idle":"2024-02-07T12:14:09.802442Z","shell.execute_reply.started":"2024-02-07T11:06:51.353974Z","shell.execute_reply":"2024-02-07T12:14:09.801285Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy: 0.84445\nClassification Report for Naive Bayes:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.85      0.84      9935\n    positive       0.85      0.84      0.84     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n\n\nRandom Forest Accuracy: 0.8472\nClassification Report for Random Forest:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.85      0.85      9935\n    positive       0.85      0.84      0.85     10065\n\n    accuracy                           0.85     20000\n   macro avg       0.85      0.85      0.85     20000\nweighted avg       0.85      0.85      0.85     20000\n\n\n\nNeural Network Accuracy: 0.8672\nClassification Report for Neural Network:\n               precision    recall  f1-score   support\n\n    negative       0.87      0.86      0.87      9935\n    positive       0.86      0.87      0.87     10065\n\n    accuracy                           0.87     20000\n   macro avg       0.87      0.87      0.87     20000\nweighted avg       0.87      0.87      0.87     20000\n\n\n\nDecision Tree Accuracy: 0.7212\nClassification Report for Decision Tree:\n               precision    recall  f1-score   support\n\n    negative       0.72      0.72      0.72      9935\n    positive       0.72      0.72      0.72     10065\n\n    accuracy                           0.72     20000\n   macro avg       0.72      0.72      0.72     20000\nweighted avg       0.72      0.72      0.72     20000\n\n\n\nGradient Boosting Accuracy: 0.81135\nClassification Report for Gradient Boosting:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.77      0.80      9935\n    positive       0.79      0.85      0.82     10065\n\n    accuracy                           0.81     20000\n   macro avg       0.81      0.81      0.81     20000\nweighted avg       0.81      0.81      0.81     20000\n\n\n\nk-NN Accuracy: 0.6262\nClassification Report for k-NN:\n               precision    recall  f1-score   support\n\n    negative       0.61      0.68      0.64      9935\n    positive       0.64      0.57      0.61     10065\n\n    accuracy                           0.63     20000\n   macro avg       0.63      0.63      0.63     20000\nweighted avg       0.63      0.63      0.63     20000\n\n\n\nStacking Accuracy: 0.86565\nClassification Report for Stacking:\n               precision    recall  f1-score   support\n\n    negative       0.86      0.87      0.87      9935\n    positive       0.87      0.86      0.87     10065\n\n    accuracy                           0.87     20000\n   macro avg       0.87      0.87      0.87     20000\nweighted avg       0.87      0.87      0.87     20000\n\n\n\nBagging Accuracy: 0.80165\nClassification Report for Bagging:\n               precision    recall  f1-score   support\n\n    negative       0.81      0.79      0.80      9935\n    positive       0.80      0.81      0.81     10065\n\n    accuracy                           0.80     20000\n   macro avg       0.80      0.80      0.80     20000\nweighted avg       0.80      0.80      0.80     20000\n\n\n\nVoting Classifier Accuracy: 0.84455\nClassification Report for Voting Classifier:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.83      0.84      9935\n    positive       0.84      0.86      0.85     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"lancaster stemmer without pos _ tf-idf vectorizer","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer \nimport pandas as pd\nfrom nltk.tokenize import word_tokenize\nfrom nltk import pos_tag\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Download NLTK resources if not already downloaded\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger')\ntrain_sentiments = pd.read_csv(\"/kaggle/input/sentiments/train.csv/train.csv\")\ntest_sentiments = pd.read_csv(\"/kaggle/input/sentiments/test.csv/test.csv\")\n\n# Text preprocessing function with stemming and POS tagging\ndef preprocess_review(review):\n    tokens = word_tokenize(review)\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token.lower() not in stop_words]\n\n    # Use LancasterStemmer for stemming\n    stemmer = LancasterStemmer()\n    tokens = [stemmer.stem(token) for token in tokens]\n\n\n    return ' '.join(tokens)\n\ntrain_sentiments['processed_reviews'] = train_sentiments['review'].apply(preprocess_review)\ntest_sentiments['processed_reviews'] = test_sentiments['review'].apply(preprocess_review)\n\n# Vectorize the text data using TF-IDF\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\ntrain_tfidf = tfidf_vectorizer.fit_transform(train_sentiments['processed_reviews'])\ntest_tfidf = tfidf_vectorizer.transform(test_sentiments['processed_reviews'] )","metadata":{"execution":{"iopub.status.busy":"2024-02-07T12:35:07.045328Z","iopub.execute_input":"2024-02-07T12:35:07.046061Z","iopub.status.idle":"2024-02-07T12:41:19.780254Z","shell.execute_reply.started":"2024-02-07T12:35:07.046028Z","shell.execute_reply":"2024-02-07T12:41:19.779267Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Naive Bayes\nnb_model = MultinomialNB()\nnb_model.fit(train_tfidf, train_sentiments['sentiment'])\nnb_predictions = nb_model.predict(test_tfidf)\nnb_accuracy = accuracy_score(test_sentiments['sentiment'], nb_predictions)\nprint(\"Naive Bayes Accuracy:\", nb_accuracy)\nprint(\"Classification Report for Naive Bayes:\\n\", classification_report(test_sentiments['sentiment'], nb_predictions))\nprint(\"\\n\")\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(train_tfidf, train_sentiments['sentiment'])\nrf_predictions = rf_model.predict(test_tfidf)\nrf_accuracy = accuracy_score(test_sentiments['sentiment'], rf_predictions)\nprint(\"Random Forest Accuracy:\", rf_accuracy)\nprint(\"Classification Report for Random Forest:\\n\", classification_report(test_sentiments['sentiment'], rf_predictions))\nprint(\"\\n\")\n\n# Neural Network\nnn_model = MLPClassifier(hidden_layer_sizes=(64,), max_iter=100, random_state=42)\nnn_model.fit(train_tfidf, train_sentiments['sentiment'])\nnn_predictions = nn_model.predict(test_tfidf)\nnn_accuracy = accuracy_score(test_sentiments['sentiment'], nn_predictions)\nprint(\"Neural Network Accuracy:\", nn_accuracy)\nprint(\"Classification Report for Neural Network:\\n\", classification_report(test_sentiments['sentiment'], nn_predictions))\nprint(\"\\n\")\n\n# Decision Tree\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(train_tfidf, train_sentiments['sentiment'])\ndt_predictions = dt_model.predict(test_tfidf)\ndt_accuracy = accuracy_score(test_sentiments['sentiment'], dt_predictions)\nprint(\"Decision Tree Accuracy:\", dt_accuracy)\nprint(\"Classification Report for Decision Tree:\\n\", classification_report(test_sentiments['sentiment'], dt_predictions))\nprint(\"\\n\")\n\n# Gradient Boosting\ngb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\ngb_model.fit(train_tfidf, train_sentiments['sentiment'])\ngb_predictions = gb_model.predict(test_tfidf)\ngb_accuracy = accuracy_score(test_sentiments['sentiment'], gb_predictions)\nprint(\"Gradient Boosting Accuracy:\", gb_accuracy)\nprint(\"Classification Report for Gradient Boosting:\\n\", classification_report(test_sentiments['sentiment'], gb_predictions))\nprint(\"\\n\")\n\n# k-NN\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(train_tfidf, train_sentiments['sentiment'])\nknn_predictions = knn_model.predict(test_tfidf)\nknn_accuracy = accuracy_score(test_sentiments['sentiment'], knn_predictions)\nprint(\"k-NN Accuracy:\", knn_accuracy)\nprint(\"Classification Report for k-NN:\\n\", classification_report(test_sentiments['sentiment'], knn_predictions))\nprint(\"\\n\")\n\n# Stacking\nstacking_model = StackingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model),('gb', gb_model)],\n    final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42)\n)\nstacking_model.fit(train_tfidf, train_sentiments['sentiment'])\nstacking_predictions = stacking_model.predict(test_tfidf)\nstacking_accuracy = accuracy_score(test_sentiments['sentiment'], stacking_predictions)\nprint(\"Stacking Accuracy:\", stacking_accuracy)\nprint(\"Classification Report for Stacking:\\n\", classification_report(test_sentiments['sentiment'], stacking_predictions))\nprint(\"\\n\")\n\n# Bagging\nbagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\nbagging_model.fit(train_tfidf, train_sentiments['sentiment'])\nbagging_predictions = bagging_model.predict(test_tfidf)\nbagging_accuracy = accuracy_score(test_sentiments['sentiment'], bagging_predictions)\nprint(\"Bagging Accuracy:\", bagging_accuracy)\nprint(\"Classification Report for Bagging:\\n\", classification_report(test_sentiments['sentiment'], bagging_predictions))\nprint(\"\\n\")\n\n# Voting Classifier\nvoting_model = VotingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model), ('gb', gb_model)],\n    voting='hard'\n)\nvoting_model.fit(train_tfidf, train_sentiments['sentiment'])\nvoting_predictions = voting_model.predict(test_tfidf)\nvoting_accuracy = accuracy_score(test_sentiments['sentiment'], voting_predictions)\nprint(\"Voting Classifier Accuracy:\", voting_accuracy)\nprint(\"Classification Report for Voting Classifier:\\n\", classification_report(test_sentiments['sentiment'], voting_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-02-07T12:42:42.720138Z","iopub.execute_input":"2024-02-07T12:42:42.720584Z","iopub.status.idle":"2024-02-07T16:18:16.501649Z","shell.execute_reply.started":"2024-02-07T12:42:42.720552Z","shell.execute_reply":"2024-02-07T16:18:16.500569Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy: 0.8503\nClassification Report for Naive Bayes:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.85      0.85      9935\n    positive       0.85      0.85      0.85     10065\n\n    accuracy                           0.85     20000\n   macro avg       0.85      0.85      0.85     20000\nweighted avg       0.85      0.85      0.85     20000\n\n\n\nRandom Forest Accuracy: 0.84525\nClassification Report for Random Forest:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.85      0.85      9935\n    positive       0.85      0.84      0.84     10065\n\n    accuracy                           0.85     20000\n   macro avg       0.85      0.85      0.85     20000\nweighted avg       0.85      0.85      0.85     20000\n\n\n\nNeural Network Accuracy: 0.8533\nClassification Report for Neural Network:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.85      0.85      9935\n    positive       0.85      0.86      0.85     10065\n\n    accuracy                           0.85     20000\n   macro avg       0.85      0.85      0.85     20000\nweighted avg       0.85      0.85      0.85     20000\n\n\n\nDecision Tree Accuracy: 0.7125\nClassification Report for Decision Tree:\n               precision    recall  f1-score   support\n\n    negative       0.71      0.72      0.71      9935\n    positive       0.72      0.71      0.71     10065\n\n    accuracy                           0.71     20000\n   macro avg       0.71      0.71      0.71     20000\nweighted avg       0.71      0.71      0.71     20000\n\n\n\nGradient Boosting Accuracy: 0.81185\nClassification Report for Gradient Boosting:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.77      0.80      9935\n    positive       0.79      0.85      0.82     10065\n\n    accuracy                           0.81     20000\n   macro avg       0.81      0.81      0.81     20000\nweighted avg       0.81      0.81      0.81     20000\n\n\n\nk-NN Accuracy: 0.74355\nClassification Report for k-NN:\n               precision    recall  f1-score   support\n\n    negative       0.75      0.72      0.74      9935\n    positive       0.74      0.77      0.75     10065\n\n    accuracy                           0.74     20000\n   macro avg       0.74      0.74      0.74     20000\nweighted avg       0.74      0.74      0.74     20000\n\n\n\nStacking Accuracy: 0.87125\nClassification Report for Stacking:\n               precision    recall  f1-score   support\n\n    negative       0.87      0.87      0.87      9935\n    positive       0.87      0.87      0.87     10065\n\n    accuracy                           0.87     20000\n   macro avg       0.87      0.87      0.87     20000\nweighted avg       0.87      0.87      0.87     20000\n\n\n\nBagging Accuracy: 0.803\nClassification Report for Bagging:\n               precision    recall  f1-score   support\n\n    negative       0.81      0.80      0.80      9935\n    positive       0.80      0.81      0.81     10065\n\n    accuracy                           0.80     20000\n   macro avg       0.80      0.80      0.80     20000\nweighted avg       0.80      0.80      0.80     20000\n\n\n\nVoting Classifier Accuracy: 0.85565\nClassification Report for Voting Classifier:\n               precision    recall  f1-score   support\n\n    negative       0.86      0.84      0.85      9935\n    positive       0.85      0.87      0.86     10065\n\n    accuracy                           0.86     20000\n   macro avg       0.86      0.86      0.86     20000\nweighted avg       0.86      0.86      0.86     20000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install spacy\n!python -m spacy download en_core_web_sm","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:18:33.887595Z","iopub.execute_input":"2024-02-08T08:18:33.887888Z","iopub.status.idle":"2024-02-08T08:19:10.058936Z","shell.execute_reply.started":"2024-02-08T08:18:33.887860Z","shell.execute_reply":"2024-02-08T08:19:10.057955Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.24.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"spacy lemmatizatio with pos _ tf-idf vectorizer","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk import pos_tag\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport spacy\n\n# Load the English language model in SpaCy\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Function for lemmatization and POS tagging\ndef preprocess_lemreview(review):\n    # Tokenize the review\n    tokens = word_tokenize(review)\n    \n    # Remove stop words\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token.lower() not in stop_words]\n\n    # Lemmatize and perform POS tagging using SpaCy\n    doc = nlp(\" \".join(tokens))\n    tokens = [token.lemma_ + '_' + token.pos_ for token in doc]\n\n    return ' '.join(tokens)\n\ntrain_sentiments = pd.read_csv(\"/kaggle/input/sentiments/train.csv/train.csv\")\ntest_sentiments = pd.read_csv(\"/kaggle/input/sentiments/test.csv/test.csv\")\n\n# Apply preprocessing to the reviews\ntrain_sentiments['processed_reviews'] = train_sentiments['review'].apply(preprocess_lemreview)\ntest_sentiments['processed_reviews'] = test_sentiments['review'].apply(preprocess_lemreview)\n\n# Vectorize the text data using TF-IDF\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\ntrain_tfidf = tfidf_vectorizer.fit_transform(train_sentiments['processed_reviews'])\ntest_tfidf = tfidf_vectorizer.transform(test_sentiments['processed_reviews'])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T08:27:52.839328Z","iopub.execute_input":"2024-02-08T08:27:52.839736Z","iopub.status.idle":"2024-02-08T08:54:06.086717Z","shell.execute_reply.started":"2024-02-08T08:27:52.839702Z","shell.execute_reply":"2024-02-08T08:54:06.085787Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\n# Naive Bayes\nnb_model = MultinomialNB()\nnb_model.fit(train_tfidf, train_sentiments['sentiment'])\nnb_predictions = nb_model.predict(test_tfidf)\nnb_accuracy = accuracy_score(test_sentiments['sentiment'], nb_predictions)\nprint(\"Naive Bayes Accuracy:\", nb_accuracy)\nprint(\"Classification Report for Naive Bayes:\\n\", classification_report(test_sentiments['sentiment'], nb_predictions))\nprint(\"\\n\")\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(train_tfidf, train_sentiments['sentiment'])\nrf_predictions = rf_model.predict(test_tfidf)\nrf_accuracy = accuracy_score(test_sentiments['sentiment'], rf_predictions)\nprint(\"Random Forest Accuracy:\", rf_accuracy)\nprint(\"Classification Report for Random Forest:\\n\", classification_report(test_sentiments['sentiment'], rf_predictions))\nprint(\"\\n\")\n\n# Neural Network\nnn_model = MLPClassifier(hidden_layer_sizes=(64,), max_iter=100, random_state=42)\nnn_model.fit(train_tfidf, train_sentiments['sentiment'])\nnn_predictions = nn_model.predict(test_tfidf)\nnn_accuracy = accuracy_score(test_sentiments['sentiment'], nn_predictions)\nprint(\"Neural Network MLP CLASSIFIER Accuracy:\", nn_accuracy)\nprint(\"Classification Report for Neural Network:\\n\", classification_report(test_sentiments['sentiment'], nn_predictions))\nprint(\"\\n\")\n\n# Decision Tree\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(train_tfidf, train_sentiments['sentiment'])\ndt_predictions = dt_model.predict(test_tfidf)\ndt_accuracy = accuracy_score(test_sentiments['sentiment'], dt_predictions)\nprint(\"Decision Tree Accuracy:\", dt_accuracy)\nprint(\"Classification Report for Decision Tree:\\n\", classification_report(test_sentiments['sentiment'], dt_predictions))\nprint(\"\\n\")\n\n# Gradient Boosting\ngb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\ngb_model.fit(train_tfidf, train_sentiments['sentiment'])\ngb_predictions = gb_model.predict(test_tfidf)\ngb_accuracy = accuracy_score(test_sentiments['sentiment'], gb_predictions)\nprint(\"Gradient Boosting Accuracy:\", gb_accuracy)\nprint(\"Classification Report for Gradient Boosting:\\n\", classification_report(test_sentiments['sentiment'], gb_predictions))\nprint(\"\\n\")\n\n# k-NN\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(train_tfidf, train_sentiments['sentiment'])\nknn_predictions = knn_model.predict(test_tfidf)\nknn_accuracy = accuracy_score(test_sentiments['sentiment'], knn_predictions)\nprint(\"k-NN Accuracy:\", knn_accuracy)\nprint(\"Classification Report for k-NN:\\n\", classification_report(test_sentiments['sentiment'], knn_predictions))\nprint(\"\\n\")\n\n# Stacking\nstacking_model = StackingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model),('gb', gb_model)],\n    final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42)\n)\nstacking_model.fit(train_tfidf, train_sentiments['sentiment'])\nstacking_predictions = stacking_model.predict(test_tfidf)\nstacking_accuracy = accuracy_score(test_sentiments['sentiment'], stacking_predictions)\nprint(\"Stacking Accuracy:\", stacking_accuracy)\nprint(\"Classification Report for Stacking:\\n\", classification_report(test_sentiments['sentiment'], stacking_predictions))\nprint(\"\\n\")\n\n# Bagging\nbagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\nbagging_model.fit(train_tfidf, train_sentiments['sentiment'])\nbagging_predictions = bagging_model.predict(test_tfidf)\nbagging_accuracy = accuracy_score(test_sentiments['sentiment'], bagging_predictions)\nprint(\"Bagging Accuracy:\", bagging_accuracy)\nprint(\"Classification Report for Bagging:\\n\", classification_report(test_sentiments['sentiment'], bagging_predictions))\nprint(\"\\n\")\n\n# Voting Classifier\nvoting_model = VotingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model), ('gb', gb_model)],\n    voting='hard'\n)\nvoting_model.fit(train_tfidf, train_sentiments['sentiment'])\nvoting_predictions = voting_model.predict(test_tfidf)\nvoting_accuracy = accuracy_score(test_sentiments['sentiment'], voting_predictions)\nprint(\"Voting Classifier Accuracy:\", voting_accuracy)\nprint(\"Classification Report for Voting Classifier:\\n\", classification_report(test_sentiments['sentiment'], voting_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T09:17:46.887376Z","iopub.execute_input":"2024-02-08T09:17:46.887947Z","iopub.status.idle":"2024-02-08T12:22:06.014735Z","shell.execute_reply.started":"2024-02-08T09:17:46.887909Z","shell.execute_reply":"2024-02-08T12:22:06.013797Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy: 0.8513\nClassification Report for Naive Bayes:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.85      0.85      9935\n    positive       0.85      0.85      0.85     10065\n\n    accuracy                           0.85     20000\n   macro avg       0.85      0.85      0.85     20000\nweighted avg       0.85      0.85      0.85     20000\n\n\n\nRandom Forest Accuracy: 0.8443\nClassification Report for Random Forest:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.85      0.85      9935\n    positive       0.85      0.83      0.84     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n\n\nNeural Network MLP CLASSIFIER Accuracy: 0.85735\nClassification Report for Neural Network:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.86      0.86      9935\n    positive       0.86      0.85      0.86     10065\n\n    accuracy                           0.86     20000\n   macro avg       0.86      0.86      0.86     20000\nweighted avg       0.86      0.86      0.86     20000\n\n\n\nDecision Tree Accuracy: 0.7083\nClassification Report for Decision Tree:\n               precision    recall  f1-score   support\n\n    negative       0.70      0.71      0.71      9935\n    positive       0.71      0.71      0.71     10065\n\n    accuracy                           0.71     20000\n   macro avg       0.71      0.71      0.71     20000\nweighted avg       0.71      0.71      0.71     20000\n\n\n\nGradient Boosting Accuracy: 0.80335\nClassification Report for Gradient Boosting:\n               precision    recall  f1-score   support\n\n    negative       0.83      0.76      0.79      9935\n    positive       0.78      0.85      0.81     10065\n\n    accuracy                           0.80     20000\n   macro avg       0.81      0.80      0.80     20000\nweighted avg       0.81      0.80      0.80     20000\n\n\n\nk-NN Accuracy: 0.60415\nClassification Report for k-NN:\n               precision    recall  f1-score   support\n\n    negative       0.62      0.54      0.58      9935\n    positive       0.60      0.67      0.63     10065\n\n    accuracy                           0.60     20000\n   macro avg       0.61      0.60      0.60     20000\nweighted avg       0.61      0.60      0.60     20000\n\n\n\nStacking Accuracy: 0.865\nClassification Report for Stacking:\n               precision    recall  f1-score   support\n\n    negative       0.86      0.87      0.86      9935\n    positive       0.87      0.86      0.87     10065\n\n    accuracy                           0.86     20000\n   macro avg       0.86      0.87      0.86     20000\nweighted avg       0.87      0.86      0.87     20000\n\n\n\nBagging Accuracy: 0.8038\nClassification Report for Bagging:\n               precision    recall  f1-score   support\n\n    negative       0.80      0.81      0.80      9935\n    positive       0.81      0.80      0.80     10065\n\n    accuracy                           0.80     20000\n   macro avg       0.80      0.80      0.80     20000\nweighted avg       0.80      0.80      0.80     20000\n\n\n\nVoting Classifier Accuracy: 0.84105\nClassification Report for Voting Classifier:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.82      0.84      9935\n    positive       0.83      0.86      0.84     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"spacy lemmatizatio without pos _ cout vectorizer","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nimport spacy\n\n# Load the English language model in SpaCy\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Function for lemmatization\ndef preprocess_lemreview(review):\n    # Tokenize the review\n    tokens = word_tokenize(review)\n    \n    # Remove stop words\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token.lower() not in stop_words]\n\n    # Lemmatize using SpaCy\n    doc = nlp(\" \".join(tokens))\n    tokens = [token.lemma_ for token in doc]\n\n    return ' '.join(tokens)\n\n# Read the CSV files\ntrain_sentiments = pd.read_csv(\"/kaggle/input/sentiments/train.csv/train.csv\")\ntest_sentiments = pd.read_csv(\"/kaggle/input/sentiments/test.csv/test.csv\")\n\n# Apply preprocessing to the reviews\ntrain_sentiments['processed_reviews'] = train_sentiments['review'].apply(preprocess_lemreview)\ntest_sentiments['processed_reviews'] = test_sentiments['review'].apply(preprocess_lemreview)\n\n# Vectorize the text data using CountVectorizer\ncount_vectorizer = CountVectorizer(max_features=5000)\ntrain_tfidf = count_vectorizer.fit_transform(train_sentiments['processed_reviews'])\ntest_tfidf = count_vectorizer.transform(test_sentiments['processed_reviews'])","metadata":{"execution":{"iopub.status.busy":"2024-02-08T12:51:57.427712Z","iopub.execute_input":"2024-02-08T12:51:57.428507Z","iopub.status.idle":"2024-02-08T13:18:41.677728Z","shell.execute_reply.started":"2024-02-08T12:51:57.428476Z","shell.execute_reply":"2024-02-08T13:18:41.676657Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\n# Naive Bayes\nnb_model = MultinomialNB()\nnb_model.fit(train_tfidf, train_sentiments['sentiment'])\nnb_predictions = nb_model.predict(test_tfidf)\nnb_accuracy = accuracy_score(test_sentiments['sentiment'], nb_predictions)\nprint(\"Naive Bayes Accuracy:\", nb_accuracy)\nprint(\"Classification Report for Naive Bayes:\\n\", classification_report(test_sentiments['sentiment'], nb_predictions))\nprint(\"\\n\")\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(train_tfidf, train_sentiments['sentiment'])\nrf_predictions = rf_model.predict(test_tfidf)\nrf_accuracy = accuracy_score(test_sentiments['sentiment'], rf_predictions)\nprint(\"Random Forest Accuracy:\", rf_accuracy)\nprint(\"Classification Report for Random Forest:\\n\", classification_report(test_sentiments['sentiment'], rf_predictions))\nprint(\"\\n\")\n\n# Neural Network\nnn_model = MLPClassifier(hidden_layer_sizes=(64,), max_iter=100, random_state=42)\nnn_model.fit(train_tfidf, train_sentiments['sentiment'])\nnn_predictions = nn_model.predict(test_tfidf)\nnn_accuracy = accuracy_score(test_sentiments['sentiment'], nn_predictions)\nprint(\"Neural Network MLP CLASSIFIER Accuracy:\", nn_accuracy)\nprint(\"Classification Report for Neural Network:\\n\", classification_report(test_sentiments['sentiment'], nn_predictions))\nprint(\"\\n\")\n\n# Decision Tree\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(train_tfidf, train_sentiments['sentiment'])\ndt_predictions = dt_model.predict(test_tfidf)\ndt_accuracy = accuracy_score(test_sentiments['sentiment'], dt_predictions)\nprint(\"Decision Tree Accuracy:\", dt_accuracy)\nprint(\"Classification Report for Decision Tree:\\n\", classification_report(test_sentiments['sentiment'], dt_predictions))\nprint(\"\\n\")\n\n# Gradient Boosting\ngb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\ngb_model.fit(train_tfidf, train_sentiments['sentiment'])\ngb_predictions = gb_model.predict(test_tfidf)\ngb_accuracy = accuracy_score(test_sentiments['sentiment'], gb_predictions)\nprint(\"Gradient Boosting Accuracy:\", gb_accuracy)\nprint(\"Classification Report for Gradient Boosting:\\n\", classification_report(test_sentiments['sentiment'], gb_predictions))\nprint(\"\\n\")\n\n# k-NN\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(train_tfidf, train_sentiments['sentiment'])\nknn_predictions = knn_model.predict(test_tfidf)\nknn_accuracy = accuracy_score(test_sentiments['sentiment'], knn_predictions)\nprint(\"k-NN Accuracy:\", knn_accuracy)\nprint(\"Classification Report for k-NN:\\n\", classification_report(test_sentiments['sentiment'], knn_predictions))\nprint(\"\\n\")\n\n# Stacking\nstacking_model = StackingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model),('gb', gb_model)],\n    final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42)\n)\nstacking_model.fit(train_tfidf, train_sentiments['sentiment'])\nstacking_predictions = stacking_model.predict(test_tfidf)\nstacking_accuracy = accuracy_score(test_sentiments['sentiment'], stacking_predictions)\nprint(\"Stacking Accuracy:\", stacking_accuracy)\nprint(\"Classification Report for Stacking:\\n\", classification_report(test_sentiments['sentiment'], stacking_predictions))\nprint(\"\\n\")\n\n# Bagging\nbagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\nbagging_model.fit(train_tfidf, train_sentiments['sentiment'])\nbagging_predictions = bagging_model.predict(test_tfidf)\nbagging_accuracy = accuracy_score(test_sentiments['sentiment'], bagging_predictions)\nprint(\"Bagging Accuracy:\", bagging_accuracy)\nprint(\"Classification Report for Bagging:\\n\", classification_report(test_sentiments['sentiment'], bagging_predictions))\nprint(\"\\n\")\n\n# Voting Classifier\nvoting_model = VotingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model), ('gb', gb_model)],\n    voting='hard'\n)\nvoting_model.fit(train_tfidf, train_sentiments['sentiment'])\nvoting_predictions = voting_model.predict(test_tfidf)\nvoting_accuracy = accuracy_score(test_sentiments['sentiment'], voting_predictions)\nprint(\"Voting Classifier Accuracy:\", voting_accuracy)\nprint(\"Classification Report for Voting Classifier:\\n\", classification_report(test_sentiments['sentiment'], voting_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T13:21:07.184419Z","iopub.execute_input":"2024-02-08T13:21:07.185320Z","iopub.status.idle":"2024-02-08T14:18:31.031548Z","shell.execute_reply.started":"2024-02-08T13:21:07.185286Z","shell.execute_reply":"2024-02-08T14:18:31.030380Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy: 0.84485\nClassification Report for Naive Bayes:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.85      0.85      9935\n    positive       0.85      0.84      0.84     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n\n\nRandom Forest Accuracy: 0.8448\nClassification Report for Random Forest:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.85      0.85      9935\n    positive       0.85      0.84      0.84     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n\n\nNeural Network MLP CLASSIFIER Accuracy: 0.8652\nClassification Report for Neural Network:\n               precision    recall  f1-score   support\n\n    negative       0.87      0.86      0.86      9935\n    positive       0.86      0.87      0.87     10065\n\n    accuracy                           0.87     20000\n   macro avg       0.87      0.87      0.87     20000\nweighted avg       0.87      0.87      0.87     20000\n\n\n\nDecision Tree Accuracy: 0.7161\nClassification Report for Decision Tree:\n               precision    recall  f1-score   support\n\n    negative       0.71      0.73      0.72      9935\n    positive       0.72      0.70      0.71     10065\n\n    accuracy                           0.72     20000\n   macro avg       0.72      0.72      0.72     20000\nweighted avg       0.72      0.72      0.72     20000\n\n\n\nGradient Boosting Accuracy: 0.8064\nClassification Report for Gradient Boosting:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.76      0.80      9935\n    positive       0.78      0.85      0.82     10065\n\n    accuracy                           0.81     20000\n   macro avg       0.81      0.81      0.81     20000\nweighted avg       0.81      0.81      0.81     20000\n\n\n\nk-NN Accuracy: 0.64195\nClassification Report for k-NN:\n               precision    recall  f1-score   support\n\n    negative       0.62      0.70      0.66      9935\n    positive       0.66      0.58      0.62     10065\n\n    accuracy                           0.64     20000\n   macro avg       0.64      0.64      0.64     20000\nweighted avg       0.64      0.64      0.64     20000\n\n\n\nStacking Accuracy: 0.86475\nClassification Report for Stacking:\n               precision    recall  f1-score   support\n\n    negative       0.86      0.87      0.86      9935\n    positive       0.87      0.86      0.87     10065\n\n    accuracy                           0.86     20000\n   macro avg       0.86      0.86      0.86     20000\nweighted avg       0.86      0.86      0.86     20000\n\n\n\nBagging Accuracy: 0.8032\nClassification Report for Bagging:\n               precision    recall  f1-score   support\n\n    negative       0.81      0.79      0.80      9935\n    positive       0.80      0.81      0.81     10065\n\n    accuracy                           0.80     20000\n   macro avg       0.80      0.80      0.80     20000\nweighted avg       0.80      0.80      0.80     20000\n\n\n\nVoting Classifier Accuracy: 0.8439\nClassification Report for Voting Classifier:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.84      0.84      9935\n    positive       0.84      0.85      0.85     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"spacy lemmatizer without pos _ cout vectorizer with modified parameters of ML modela","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nimport spacy\n\n# Load the English language model in SpaCy\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Function for lemmatization\ndef preprocess_lemreview(review):\n    # Tokenize the review\n    tokens = word_tokenize(review)\n    \n    # Remove stop words\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token.lower() not in stop_words]\n\n    # Lemmatize using SpaCy\n    doc = nlp(\" \".join(tokens))\n    tokens = [token.lemma_ for token in doc]\n\n    return ' '.join(tokens)\n\n# Read the CSV files\ntrain_sentiments = pd.read_csv(\"/kaggle/input/sentiments/train.csv/train.csv\")\ntest_sentiments = pd.read_csv(\"/kaggle/input/sentiments/test.csv/test.csv\")\n\n# Apply preprocessing to the reviews\ntrain_sentiments['processed_reviews'] = train_sentiments['review'].apply(preprocess_lemreview)\ntest_sentiments['processed_reviews'] = test_sentiments['review'].apply(preprocess_lemreview)\n\n# Vectorize the text data using CountVectorizer\ncount_vectorizer = CountVectorizer(max_features=5000)\ntrain_tfidf = count_vectorizer.fit_transform(train_sentiments['processed_reviews'])\ntest_tfidf = count_vectorizer.transform(test_sentiments['processed_reviews'])","metadata":{"execution":{"iopub.status.busy":"2024-02-11T06:36:45.957780Z","iopub.execute_input":"2024-02-11T06:36:45.958116Z","iopub.status.idle":"2024-02-11T07:06:20.530229Z","shell.execute_reply.started":"2024-02-11T06:36:45.958082Z","shell.execute_reply":"2024-02-11T07:06:20.529282Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.neural_network import MLPClassifier\n\n# Naive Bayes\nnb_model = MultinomialNB(alpha=0.1) \nnb_model.fit(train_tfidf, train_sentiments['sentiment'])\nnb_predictions = nb_model.predict(test_tfidf)\nnb_accuracy = accuracy_score(test_sentiments['sentiment'], nb_predictions)\nprint(\"Naive Bayes Accuracy:\", nb_accuracy)\nprint(\"Classification Report for Naive Bayes:\\n\", classification_report(test_sentiments['sentiment'], nb_predictions))\nprint(\"\\n\")\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42) \nrf_model.fit(train_tfidf, train_sentiments['sentiment'])\nrf_predictions = rf_model.predict(test_tfidf)\nrf_accuracy = accuracy_score(test_sentiments['sentiment'], rf_predictions)\nprint(\"Random Forest Accuracy:\", rf_accuracy)\nprint(\"Classification Report for Random Forest:\\n\", classification_report(test_sentiments['sentiment'], rf_predictions))\nprint(\"\\n\")\n\n# Neural Network\nnn_model =  MLPClassifier(hidden_layer_sizes=(128,), max_iter=200, alpha=0.0001, random_state=42)\nnn_model.fit(train_tfidf, train_sentiments['sentiment'])\nnn_predictions = nn_model.predict(test_tfidf)\nnn_accuracy = accuracy_score(test_sentiments['sentiment'], nn_predictions)\nprint(\"Neural Network MLP CLASSIFIER Accuracy:\", nn_accuracy)\nprint(\"Classification Report for Neural Network:\\n\", classification_report(test_sentiments['sentiment'], nn_predictions))\nprint(\"\\n\")\n\n# Decision Tree\ndt_model =  DecisionTreeClassifier(max_depth=10, min_samples_split=10, random_state=42)\ndt_model.fit(train_tfidf, train_sentiments['sentiment'])\ndt_predictions = dt_model.predict(test_tfidf)\ndt_accuracy = accuracy_score(test_sentiments['sentiment'], dt_predictions)\nprint(\"Decision Tree Accuracy:\", dt_accuracy)\nprint(\"Classification Report for Decision Tree:\\n\", classification_report(test_sentiments['sentiment'], dt_predictions))\nprint(\"\\n\")\n\n# Gradient Boosting\ngb_model = GradientBoostingClassifier(n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\ngb_model.fit(train_tfidf, train_sentiments['sentiment'])\ngb_predictions = gb_model.predict(test_tfidf)\ngb_accuracy = accuracy_score(test_sentiments['sentiment'], gb_predictions)\nprint(\"Gradient Boosting Accuracy:\", gb_accuracy)\nprint(\"Classification Report for Gradient Boosting:\\n\", classification_report(test_sentiments['sentiment'], gb_predictions))\nprint(\"\\n\")\n\n# k-NN\nknn_model = KNeighborsClassifier(n_neighbors=10)\nknn_model.fit(train_tfidf, train_sentiments['sentiment'])\nknn_predictions = knn_model.predict(test_tfidf)\nknn_accuracy = accuracy_score(test_sentiments['sentiment'], knn_predictions)\nprint(\"k-NN Accuracy:\", knn_accuracy)\nprint(\"Classification Report for k-NN:\\n\", classification_report(test_sentiments['sentiment'], knn_predictions))\nprint(\"\\n\")\n\n# Stacking\nstacking_model = StackingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model),('gb', gb_model)],\n    final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42)\n)\nstacking_model.fit(train_tfidf, train_sentiments['sentiment'])\nstacking_predictions = stacking_model.predict(test_tfidf)\nstacking_accuracy = accuracy_score(test_sentiments['sentiment'], stacking_predictions)\nprint(\"Stacking Accuracy:\", stacking_accuracy)\nprint(\"Classification Report for Stacking:\\n\", classification_report(test_sentiments['sentiment'], stacking_predictions))\nprint(\"\\n\")\n\n# Bagging\nbagging_model = BaggingClassifier(estimator= ExtraTreesClassifier(), n_estimators=200, random_state=42)\nbagging_model.fit(train_tfidf, train_sentiments['sentiment'])\nbagging_predictions = bagging_model.predict(test_tfidf)\nbagging_accuracy = accuracy_score(test_sentiments['sentiment'], bagging_predictions)\nprint(\"Bagging Accuracy:\", bagging_accuracy)\nprint(\"Classification Report for Bagging:\\n\", classification_report(test_sentiments['sentiment'], bagging_predictions))\nprint(\"\\n\")\n\n# Voting Classifier\nvoting_model = VotingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model), ('gb', gb_model), ('st', stacking_model)],\n    voting='hard'\n)\nvoting_model.fit(train_tfidf, train_sentiments['sentiment'])\nvoting_predictions = voting_model.predict(test_tfidf)\nvoting_accuracy = accuracy_score(test_sentiments['sentiment'], voting_predictions)\nprint(\"Voting Classifier Accuracy:\", voting_accuracy)\nprint(\"Classification Report for Voting Classifier:\\n\", classification_report(test_sentiments['sentiment'], voting_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-02-11T07:12:02.960572Z","iopub.execute_input":"2024-02-11T07:12:02.960980Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy: 0.8446\nClassification Report for Naive Bayes:\n               precision    recall  f1-score   support\n\n    negative       0.84      0.85      0.84      9935\n    positive       0.85      0.84      0.84     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n\n\nRandom Forest Accuracy: 0.82905\nClassification Report for Random Forest:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.80      0.82      9935\n    positive       0.81      0.86      0.83     10065\n\n    accuracy                           0.83     20000\n   macro avg       0.83      0.83      0.83     20000\nweighted avg       0.83      0.83      0.83     20000\n\n\n\nNeural Network MLP CLASSIFIER Accuracy: 0.8728\nClassification Report for Neural Network:\n               precision    recall  f1-score   support\n\n    negative       0.88      0.87      0.87      9935\n    positive       0.87      0.88      0.87     10065\n\n    accuracy                           0.87     20000\n   macro avg       0.87      0.87      0.87     20000\nweighted avg       0.87      0.87      0.87     20000\n\n\n\nDecision Tree Accuracy: 0.7378\nClassification Report for Decision Tree:\n               precision    recall  f1-score   support\n\n    negative       0.79      0.64      0.71      9935\n    positive       0.70      0.83      0.76     10065\n\n    accuracy                           0.74     20000\n   macro avg       0.75      0.74      0.74     20000\nweighted avg       0.75      0.74      0.74     20000\n\n\n\nGradient Boosting Accuracy: 0.84685\nClassification Report for Gradient Boosting:\n               precision    recall  f1-score   support\n\n    negative       0.86      0.82      0.84      9935\n    positive       0.83      0.87      0.85     10065\n\n    accuracy                           0.85     20000\n   macro avg       0.85      0.85      0.85     20000\nweighted avg       0.85      0.85      0.85     20000\n\n\n\nk-NN Accuracy: 0.64515\nClassification Report for k-NN:\n               precision    recall  f1-score   support\n\n    negative       0.61      0.79      0.69      9935\n    positive       0.71      0.50      0.59     10065\n\n    accuracy                           0.65     20000\n   macro avg       0.66      0.65      0.64     20000\nweighted avg       0.66      0.65      0.64     20000\n\n\n\nStacking Accuracy: 0.86975\nClassification Report for Stacking:\n               precision    recall  f1-score   support\n\n    negative       0.87      0.87      0.87      9935\n    positive       0.87      0.87      0.87     10065\n\n    accuracy                           0.87     20000\n   macro avg       0.87      0.87      0.87     20000\nweighted avg       0.87      0.87      0.87     20000\n\n\n\n","output_type":"stream"}]}]}