{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7612042,"sourceType":"datasetVersion","datasetId":4432603}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"snowball stemmer with pos, tf-idf vectorizer, normalization(minmax scaler), improved ML parameters","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nimport pandas as pd\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer\nfrom nltk import pos_tag\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Download NLTK resources if not already downloaded\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger')\n\n# Read the CSV files\ntrain_sentiments = pd.read_csv(\"/kaggle/input/data-ml/train/train.csv\")\ntest_sentiments = pd.read_csv(\"/kaggle/input/data-ml/test/test.csv\")\n\n# Text preprocessing function with stemming and POS tagging\ndef preprocess_review(review):\n    tokens = word_tokenize(review)\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token.lower() not in stop_words]\n\n    # Use SnowballStemmer for stemming\n    stemmer = SnowballStemmer('english')\n    tokens = [stemmer.stem(token) for token in tokens]\n\n    # Perform POS tagging\n    pos_tags = pos_tag(tokens)\n    tokens = [word + '_' + pos for word, pos in pos_tags]\n\n    return ' '.join(tokens)\n\ntrain_sentiments['processed_reviews'] = train_sentiments['review'].apply(preprocess_review)\ntest_sentiments['processed_reviews'] = test_sentiments['review'].apply(preprocess_review)\n\n# Vectorize the text data using TF-IDF\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\ntrain_tfidf = tfidf_vectorizer.fit_transform(train_sentiments['processed_reviews'])\ntest_tfidf = tfidf_vectorizer.transform(test_sentiments['processed_reviews'] )\n\n# Perform Min-Max scaling for normalization\nscaler = MinMaxScaler()\ntrain_tfidf = scaler.fit_transform(train_tfidf.toarray())\ntest_tfidf= scaler.transform(test_tfidf.toarray())\n\n# You can use train_tfidf_scaled and test_tfidf_scaled for further processing\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-12T18:47:57.754389Z","iopub.execute_input":"2024-02-12T18:47:57.755049Z","iopub.status.idle":"2024-02-12T19:05:23.182092Z","shell.execute_reply.started":"2024-02-12T18:47:57.755013Z","shell.execute_reply":"2024-02-12T19:05:23.180451Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.neural_network import MLPClassifier\n\n# Naive Bayes\nnb_model = MultinomialNB(alpha=0.1) \nnb_model.fit(train_tfidf, train_sentiments['sentiment'])\nnb_predictions = nb_model.predict(test_tfidf)\nnb_accuracy = accuracy_score(test_sentiments['sentiment'], nb_predictions)\nprint(\"Naive Bayes Accuracy:\", nb_accuracy)\nprint(\"Classification Report for Naive Bayes:\\n\", classification_report(test_sentiments['sentiment'], nb_predictions))\nprint(\"\\n\")\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42) \nrf_model.fit(train_tfidf, train_sentiments['sentiment'])\nrf_predictions = rf_model.predict(test_tfidf)\nrf_accuracy = accuracy_score(test_sentiments['sentiment'], rf_predictions)\nprint(\"Random Forest Accuracy:\", rf_accuracy)\nprint(\"Classification Report for Random Forest:\\n\", classification_report(test_sentiments['sentiment'], rf_predictions))\nprint(\"\\n\")\n\n# Neural Network\nnn_model =  MLPClassifier(hidden_layer_sizes=(128,), max_iter=200, alpha=0.0001, random_state=42)\nnn_model.fit(train_tfidf, train_sentiments['sentiment'])\nnn_predictions = nn_model.predict(test_tfidf)\nnn_accuracy = accuracy_score(test_sentiments['sentiment'], nn_predictions)\nprint(\"Neural Network MLP CLASSIFIER Accuracy:\", nn_accuracy)\nprint(\"Classification Report for Neural Network:\\n\", classification_report(test_sentiments['sentiment'], nn_predictions))\nprint(\"\\n\")\n\n# Decision Tree\ndt_model =  DecisionTreeClassifier(max_depth=10, min_samples_split=10, random_state=42)\ndt_model.fit(train_tfidf, train_sentiments['sentiment'])\ndt_predictions = dt_model.predict(test_tfidf)\ndt_accuracy = accuracy_score(test_sentiments['sentiment'], dt_predictions)\nprint(\"Decision Tree Accuracy:\", dt_accuracy)\nprint(\"Classification Report for Decision Tree:\\n\", classification_report(test_sentiments['sentiment'], dt_predictions))\nprint(\"\\n\")\n\n# Gradient Boosting\ngb_model = GradientBoostingClassifier(n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\ngb_model.fit(train_tfidf, train_sentiments['sentiment'])\ngb_predictions = gb_model.predict(test_tfidf)\ngb_accuracy = accuracy_score(test_sentiments['sentiment'], gb_predictions)\nprint(\"Gradient Boosting Accuracy:\", gb_accuracy)\nprint(\"Classification Report for Gradient Boosting:\\n\", classification_report(test_sentiments['sentiment'], gb_predictions))\nprint(\"\\n\")\n\n# k-NN\nknn_model = KNeighborsClassifier(n_neighbors=10)\nknn_model.fit(train_tfidf, train_sentiments['sentiment'])\nknn_predictions = knn_model.predict(test_tfidf)\nknn_accuracy = accuracy_score(test_sentiments['sentiment'], knn_predictions)\nprint(\"k-NN Accuracy:\", knn_accuracy)\nprint(\"Classification Report for k-NN:\\n\", classification_report(test_sentiments['sentiment'], knn_predictions))\nprint(\"\\n\")\n\n# Stacking\nstacking_model = StackingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model),('gb', gb_model)],\n    final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42)\n)\nstacking_model.fit(train_tfidf, train_sentiments['sentiment'])\nstacking_predictions = stacking_model.predict(test_tfidf)\nstacking_accuracy = accuracy_score(test_sentiments['sentiment'], stacking_predictions)\nprint(\"Stacking Accuracy:\", stacking_accuracy)\nprint(\"Classification Report for Stacking:\\n\", classification_report(test_sentiments['sentiment'], stacking_predictions))\nprint(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-02-12T19:05:23.184949Z","iopub.execute_input":"2024-02-12T19:05:23.185346Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2024-02-12 19:05:23.750646: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-12 19:05:23.750792: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-12 19:05:23.754404: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Naive Bayes Accuracy: 0.8446\nClassification Report for Naive Bayes:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.84      0.84      9935\n    positive       0.84      0.85      0.85     10065\n\n    accuracy                           0.84     20000\n   macro avg       0.84      0.84      0.84     20000\nweighted avg       0.84      0.84      0.84     20000\n\n\n\nRandom Forest Accuracy: 0.8209\nClassification Report for Random Forest:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.78      0.81      9935\n    positive       0.80      0.86      0.83     10065\n\n    accuracy                           0.82     20000\n   macro avg       0.82      0.82      0.82     20000\nweighted avg       0.82      0.82      0.82     20000\n\n\n\nNeural Network MLP CLASSIFIER Accuracy: 0.85665\nClassification Report for Neural Network:\n               precision    recall  f1-score   support\n\n    negative       0.86      0.86      0.86      9935\n    positive       0.86      0.86      0.86     10065\n\n    accuracy                           0.86     20000\n   macro avg       0.86      0.86      0.86     20000\nweighted avg       0.86      0.86      0.86     20000\n\n\n\nDecision Tree Accuracy: 0.7263\nClassification Report for Decision Tree:\n               precision    recall  f1-score   support\n\n    negative       0.79      0.61      0.69      9935\n    positive       0.69      0.84      0.76     10065\n\n    accuracy                           0.73     20000\n   macro avg       0.74      0.73      0.72     20000\nweighted avg       0.74      0.73      0.72     20000\n\n\n\nGradient Boosting Accuracy: 0.83305\nClassification Report for Gradient Boosting:\n               precision    recall  f1-score   support\n\n    negative       0.85      0.81      0.83      9935\n    positive       0.82      0.86      0.84     10065\n\n    accuracy                           0.83     20000\n   macro avg       0.83      0.83      0.83     20000\nweighted avg       0.83      0.83      0.83     20000\n\n\n\nk-NN Accuracy: 0.50195\nClassification Report for k-NN:\n               precision    recall  f1-score   support\n\n    negative       0.50      1.00      0.67      9935\n    positive       0.77      0.01      0.03     10065\n\n    accuracy                           0.50     20000\n   macro avg       0.63      0.51      0.35     20000\nweighted avg       0.63      0.50      0.34     20000\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Bagging\nbagging_model = BaggingClassifier(estimator= ExtraTreesClassifier(), n_estimators=200, random_state=42)\nbagging_model.fit(train_tfidf, train_sentiments['sentiment'])\nbagging_predictions = bagging_model.predict(test_tfidf)\nbagging_accuracy = accuracy_score(test_sentiments['sentiment'], bagging_predictions)\nprint(\"Bagging Accuracy:\", bagging_accuracy)\nprint(\"Classification Report for Bagging:\\n\", classification_report(test_sentiments['sentiment'], bagging_predictions))\nprint(\"\\n\")\n\n# Voting Classifier\nvoting_model = VotingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model), ('gb', gb_model), ('st', stacking_model)],\n    voting='hard'\n)\nvoting_model.fit(train_tfidf, train_sentiments['sentiment'])\nvoting_predictions = voting_model.predict(test_tfidf)\nvoting_accuracy = accuracy_score(test_sentiments['sentiment'], voting_predictions)\nprint(\"Voting Classifier Accuracy:\", voting_accuracy)\nprint(\"Classification Report for Voting Classifier:\\n\", classification_report(test_sentiments['sentiment'], voting_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"snowball stemmer with pos, tf-idf vectorizer, normalization( robust scaler), improved ML parameters","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nimport pandas as pd\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer\nfrom nltk import pos_tag\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import RobustScaler\n\n# Download NLTK resources if not already downloaded\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger')\n\ntrain_sentiments = pd.read_csv(\"/kaggle/input/data-ml/train/train.csv\")\ntest_sentiments = pd.read_csv(\"/kaggle/input/data-ml/test/test.csv\")\n\n# Text preprocessing function with stemming and POS tagging\ndef preprocess_review(review):\n    tokens = word_tokenize(review)\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token.lower() not in stop_words]\n\n    # Use SnowballStemmer for stemming\n    stemmer = SnowballStemmer('english')\n    tokens = [stemmer.stem(token) for token in tokens]\n\n    # Perform POS tagging\n    pos_tags = pos_tag(tokens)\n    tokens = [word + '_' + pos for word, pos in pos_tags]\n\n    return ' '.join(tokens)\n\ntrain_sentiments['processed_reviews'] = train_sentiments['review'].apply(preprocess_review)\ntest_sentiments['processed_reviews'] = test_sentiments['review'].apply(preprocess_review)\n\n# Vectorize the text data using TF-IDF\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\ntrain_tfidf = tfidf_vectorizer.fit_transform(train_sentiments['processed_reviews'])\ntest_tfidf = tfidf_vectorizer.transform(test_sentiments['processed_reviews'] )\n\n# Perform robust scaling for normalization\nscaler = RobustScaler()\ntrain_tfidf = scaler.fit_transform(train_tfidf.toarray())\ntest_tfidf = scaler.transform(test_tfidf.toarray())\n\n# You can use train_tfidf_scaled and test_tfidf_scaled for further processing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nimport time\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.neural_network import MLPClassifier\n\nstart = time.time()\n# Naive Bayes\nnb_model = MultinomialNB(alpha=0.1) \nnb_model.fit(train_tfidf, train_sentiments['sentiment'])\nnb_predictions = nb_model.predict(test_tfidf)\nend = time.time()\nnb_accuracy = accuracy_score(test_sentiments['sentiment'], nb_predictions)\nprint(\"Naive Bayes Accuracy:\", nb_accuracy)\nprint(\"Classification Report for Naive Bayes:\\n\", classification_report(test_sentiments['sentiment'], nb_predictions))\nprint(\"\\n\")\nprint(start - end)\n\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42) \nrf_model.fit(train_tfidf, train_sentiments['sentiment'])\nrf_predictions = rf_model.predict(test_tfidf)\nrf_accuracy = accuracy_score(test_sentiments['sentiment'], rf_predictions)\nprint(\"Random Forest Accuracy:\", rf_accuracy)\nprint(\"Classification Report for Random Forest:\\n\", classification_report(test_sentiments['sentiment'], rf_predictions))\nprint(\"\\n\")\n\n# Neural Network\nnn_model =  MLPClassifier(hidden_layer_sizes=(128,), max_iter=200, alpha=0.0001, random_state=42)\nnn_model.fit(train_tfidf, train_sentiments['sentiment'])\nnn_predictions = nn_model.predict(test_tfidf)\nnn_accuracy = accuracy_score(test_sentiments['sentiment'], nn_predictions)\nprint(\"Neural Network MLP CLASSIFIER Accuracy:\", nn_accuracy)\nprint(\"Classification Report for Neural Network:\\n\", classification_report(test_sentiments['sentiment'], nn_predictions))\nprint(\"\\n\")\n\n# Decision Tree\ndt_model =  DecisionTreeClassifier(max_depth=10, min_samples_split=10, random_state=42)\ndt_model.fit(train_tfidf, train_sentiments['sentiment'])\ndt_predictions = dt_model.predict(test_tfidf)\ndt_accuracy = accuracy_score(test_sentiments['sentiment'], dt_predictions)\nprint(\"Decision Tree Accuracy:\", dt_accuracy)\nprint(\"Classification Report for Decision Tree:\\n\", classification_report(test_sentiments['sentiment'], dt_predictions))\nprint(\"\\n\")\n\n# Gradient Boosting\ngb_model = GradientBoostingClassifier(n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\ngb_model.fit(train_tfidf, train_sentiments['sentiment'])\ngb_predictions = gb_model.predict(test_tfidf)\ngb_accuracy = accuracy_score(test_sentiments['sentiment'], gb_predictions)\nprint(\"Gradient Boosting Accuracy:\", gb_accuracy)\nprint(\"Classification Report for Gradient Boosting:\\n\", classification_report(test_sentiments['sentiment'], gb_predictions))\nprint(\"\\n\")\n\n# k-NN\nknn_model = KNeighborsClassifier(n_neighbors=10)\nknn_model.fit(train_tfidf, train_sentiments['sentiment'])\nknn_predictions = knn_model.predict(test_tfidf)\nknn_accuracy = accuracy_score(test_sentiments['sentiment'], knn_predictions)\nprint(\"k-NN Accuracy:\", knn_accuracy)\nprint(\"Classification Report for k-NN:\\n\", classification_report(test_sentiments['sentiment'], knn_predictions))\nprint(\"\\n\")\n\n# Stacking\nstacking_model = StackingClassifier(\n    estimators=[('nb', nb_model), ('rf', rf_model), ('knn', knn_model), ('dt', dt_model),('gb', gb_model)],\n    final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42)\n)\nstacking_model.fit(train_tfidf, train_sentiments['sentiment'])\nstacking_predictions = stacking_model.predict(test_tfidf)\nstacking_accuracy = accuracy_score(test_sentiments['sentiment'], stacking_predictions)\nprint(\"Stacking Accuracy:\", stacking_accuracy)\nprint(\"Classification Report for Stacking:\\n\", classification_report(test_sentiments['sentiment'], stacking_predictions))\nprint(\"\\n\")","metadata":{},"execution_count":null,"outputs":[]}]}